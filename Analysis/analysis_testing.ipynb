{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import uproot\n",
    "import awkward as ak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 1\n",
    "input_dir = \"C:/Users/luke/OneDrive/Documents/MPhys Project/Output Files/y_2_05_offset_test/\"\n",
    "\n",
    "offsets_y = np.loadtxt(input_dir + \"offsets_test_y.csv\", delimiter = \",\")\n",
    "offsets_z = np.loadtxt(input_dir + \"offsets_test_z.csv\", delimiter = \",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import uproot\n",
    "import awkward as ak\n",
    "\n",
    "def Shift_NaNs(input_array):\n",
    "    \n",
    "    nan_mask = np.isnan(input_array)\n",
    "    output_array = np.array([np.concatenate((row[nan_mask_row], row[~nan_mask_row])) for row, nan_mask_row in zip(input_array, nan_mask)])\n",
    "\n",
    "    return output_array\n",
    "\n",
    "def Process_Coords(input_ak_array):\n",
    "    return Shift_NaNs(ak.to_numpy(ak.pad_none(input_ak_array, target = 6, clip=True)).filled(np.nan))\n",
    "    \n",
    "def Generate_DataFrame_From_ROOT(input_dir, i):\n",
    "\n",
    "    output_path = input_dir + \"df\" + str(i) + \".csv\"\n",
    "    trackstates_path = input_dir + str(i) + \"/trackstates_fitter.root\"\n",
    "    tracksummary_path = input_dir + str(i) + \"/tracksummary_fitter.root\"\n",
    "\n",
    "    file = uproot.open(trackstates_path)\n",
    "    tree_input = file[\"trackstates\"]\n",
    "\n",
    "    X_TRUTH = Process_Coords(tree_input[\"t_x\"].array())\n",
    "    GLOBAL_X_HIT = Process_Coords(tree_input[\"g_x_hit\"].array())\n",
    "    FIT_X_HIT = Process_Coords(tree_input[\"g_x_smt\"].array())\n",
    "\n",
    "    Y_TRUTH = Process_Coords(tree_input[\"t_y\"].array())\n",
    "    GLOBAL_Y_HIT = Process_Coords(tree_input[\"g_y_hit\"].array())\n",
    "    FIT_Y_HIT = Process_Coords(tree_input[\"g_y_smt\"].array())\n",
    "\n",
    "    Z_TRUTH = Process_Coords(tree_input[\"t_z\"].array())\n",
    "    GLOBAL_Z_HIT = Process_Coords(tree_input[\"g_z_hit\"].array())\n",
    "    FIT_Z_HIT = Process_Coords(tree_input[\"g_z_smt\"].array())\n",
    "\n",
    "    FIT_PX = Process_Coords(tree_input[\"px_smt\"].array())\n",
    "    FIT_PY = Process_Coords(tree_input[\"py_smt\"].array())\n",
    "    FIT_PZ = Process_Coords(tree_input[\"pz_smt\"].array())\n",
    "\n",
    "    file.close()\n",
    "\n",
    "    file = uproot.open(tracksummary_path)\n",
    "    tree_input = file[\"tracksummary\"]\n",
    "\n",
    "    QOP_FIT = ak.to_numpy(ak.flatten(tree_input[\"eQOP_fit\"].array()))\n",
    "    PHI_FIT = ak.to_numpy(ak.flatten(tree_input[\"ePHI_fit\"].array()))\n",
    "    THETA_FIT = ak.to_numpy(ak.flatten(tree_input[\"eTHETA_fit\"].array()))\n",
    "\n",
    "    P_TRUTH = ak.to_numpy(ak.flatten(tree_input[\"t_p\"].array()))\n",
    "    Q_TRUTH = ak.to_numpy(ak.flatten(tree_input[\"t_charge\"].array()))\n",
    "    PZ_TRUTH = ak.to_numpy(ak.flatten(tree_input[\"t_pz\"].array()))\n",
    "    PHI_TRUTH = ak.to_numpy(ak.flatten(tree_input[\"t_phi\"].array()))\n",
    "    THETA_TRUTH = ak.to_numpy(ak.flatten(tree_input[\"t_theta\"].array()))\n",
    "\n",
    "    CHI2SUM = ak.to_numpy(ak.flatten(tree_input[\"chi2Sum\"].array()))\n",
    "    NDF = ak.to_numpy(ak.flatten(tree_input[\"NDF\"].array()))\n",
    "\n",
    "    file.close()\n",
    "\n",
    "    P_FIT = Q_TRUTH/QOP_FIT\n",
    "    PZ_FIT = P_FIT*np.cos(THETA_FIT)\n",
    "\n",
    "    df_columns = [\n",
    "                \"QOP_FIT\", \"PHI_FIT\", \"THETA_FIT\", \"P_FIT\", \"PZ_FIT\", \n",
    "                \"P_TRUTH\", \"Q_TRUTH\", \"PZ_TRUTH\", \"PHI_TRUTH\", \"THETA_TRUTH\", \n",
    "                \"CHI2SUM\", \"NDF\", \n",
    "                \"FIT_PX_6\", \"FIT_PX_5\", \"FIT_PX_4\", \"FIT_PX_3\", \"FIT_PX_2\", \"FIT_PX_1\",\n",
    "                \"FIT_PY_6\", \"FIT_PY_5\", \"FIT_PY_4\", \"FIT_PY_3\", \"FIT_PY_2\", \"FIT_PY_1\",\n",
    "                \"FIT_PZ_6\", \"FIT_PZ_5\", \"FIT_PZ_4\", \"FIT_PZ_3\", \"FIT_PZ_2\", \"FIT_PZ_1\", \n",
    "                \"X_TRUTH_6\", \"X_TRUTH_5\", \"X_TRUTH_4\", \"X_TRUTH_3\", \"X_TRUTH_2\", \"X_TRUTH_1\", \n",
    "                \"GLOBAL_X_HIT_6\", \"GLOBAL_X_HIT_5\", \"GLOBAL_X_HIT_4\", \"GLOBAL_X_HIT_3\", \"GLOBAL_X_HIT_2\", \"GLOBAL_X_HIT_1\",\n",
    "                \"FIT_X_HIT_6\", \"FIT_X_HIT_5\", \"FIT_X_HIT_4\", \"FIT_X_HIT_3\", \"FIT_X_HIT_2\", \"FIT_X_HIT_1\", \n",
    "                \"Y_TRUTH_6\", \"Y_TRUTH_5\", \"Y_TRUTH_4\", \"Y_TRUTH_3\", \"Y_TRUTH_2\", \"Y_TRUTH_1\", \n",
    "                \"GLOBAL_Y_HIT_6\", \"GLOBAL_Y_HIT_5\", \"GLOBAL_Y_HIT_4\", \"GLOBAL_Y_HIT_3\", \"GLOBAL_Y_HIT_2\", \"GLOBAL_Y_HIT_1\", \n",
    "                \"FIT_Y_HIT_6\", \"FIT_Y_HIT_5\", \"FIT_Y_HIT_4\", \"FIT_Y_HIT_3\", \"FIT_Y_HIT_2\", \"FIT_Y_HIT_1\",\n",
    "                \"Z_TRUTH_6\", \"Z_TRUTH_5\", \"Z_TRUTH_4\", \"Z_TRUTH_3\", \"Z_TRUTH_2\", \"Z_TRUTH_1\", \n",
    "                \"GLOBAL_Z_HIT_6\", \"GLOBAL_Z_HIT_5\", \"GLOBAL_Z_HIT_4\", \"GLOBAL_Z_HIT_3\", \"GLOBAL_Z_HIT_2\", \"GLOBAL_Z_HIT_1\",\n",
    "                \"FIT_Z_HIT_6\", \"FIT_Z_HIT_5\", \"FIT_Z_HIT_4\", \"FIT_Z_HIT_3\", \"FIT_Z_HIT_2\", \"FIT_Z_HIT_1\"\n",
    "    ]\n",
    "\n",
    "    df_data = [\n",
    "                QOP_FIT, PHI_FIT, THETA_FIT, P_FIT, PZ_FIT,\n",
    "                P_TRUTH, Q_TRUTH, PZ_TRUTH, PHI_TRUTH, THETA_TRUTH, \n",
    "                CHI2SUM, NDF, \n",
    "                FIT_PX[:,0], FIT_PX[:,1], FIT_PX[:,2], FIT_PX[:,3], FIT_PX[:,4], FIT_PX[:,5], \n",
    "                FIT_PY[:,0], FIT_PY[:,1], FIT_PY[:,2], FIT_PY[:,3], FIT_PY[:,4], FIT_PY[:,5], \n",
    "                FIT_PZ[:,0], FIT_PZ[:,1], FIT_PZ[:,2], FIT_PZ[:,3], FIT_PZ[:,4], FIT_PZ[:,5], \n",
    "                X_TRUTH[:,0], X_TRUTH[:,1], X_TRUTH[:,2], X_TRUTH[:,3], X_TRUTH[:,4], X_TRUTH[:,5], \n",
    "                GLOBAL_X_HIT[:,0], GLOBAL_X_HIT[:,1], GLOBAL_X_HIT[:,2], GLOBAL_X_HIT[:,3], GLOBAL_X_HIT[:,4], GLOBAL_X_HIT[:,5], \n",
    "                FIT_X_HIT[:,0], FIT_X_HIT[:,1], FIT_X_HIT[:,2], FIT_X_HIT[:,3], FIT_X_HIT[:,4], FIT_X_HIT[:,5],  \n",
    "                Y_TRUTH[:,0], Y_TRUTH[:,1], Y_TRUTH[:,2], Y_TRUTH[:,3], Y_TRUTH[:,4], Y_TRUTH[:,5], \n",
    "                GLOBAL_Y_HIT[:,0], GLOBAL_Y_HIT[:,1], GLOBAL_Y_HIT[:,2], GLOBAL_Y_HIT[:,3], GLOBAL_Y_HIT[:,4], GLOBAL_Y_HIT[:,5],\n",
    "                FIT_Y_HIT[:,0], FIT_Y_HIT[:,1], FIT_Y_HIT[:,2], FIT_Y_HIT[:,3], FIT_Y_HIT[:,4], FIT_Y_HIT[:,5],  \n",
    "                Z_TRUTH[:,0], Z_TRUTH[:,1], Z_TRUTH[:,2], Z_TRUTH[:,3], Z_TRUTH[:,4], Z_TRUTH[:,5], \n",
    "                GLOBAL_Z_HIT[:,0], GLOBAL_Z_HIT[:,1], GLOBAL_Z_HIT[:,2], GLOBAL_Z_HIT[:,3], GLOBAL_Z_HIT[:,4], GLOBAL_Z_HIT[:,5],\n",
    "                FIT_Z_HIT[:,0], FIT_Z_HIT[:,1], FIT_Z_HIT[:,2], FIT_Z_HIT[:,3], FIT_Z_HIT[:,4], FIT_Z_HIT[:,5],  \n",
    "    ]\n",
    "\n",
    "    df = pd.DataFrame(data=np.column_stack(df_data), columns=df_columns)\n",
    "    df.to_csv(output_path)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "\n",
    "def Fit_Gaussian(x):\n",
    "\n",
    "    x_no_nan = x[~np.isnan(x)]\n",
    "    mu, std = norm.fit(x_no_nan)\n",
    "\n",
    "    return x_no_nan, mu, std\n",
    "\n",
    "def Residual_Plot(x, label = \"\", save = False, bins=100):\n",
    "    \"\"\"\n",
    "    Residual_Plot takes a 1D input of data and plots it as a frequency density histogram, overlaying a fitted normal distribution.\n",
    "\n",
    "    Inputs\n",
    "    x: 1D input data, Pandas series or Numpy array\n",
    "    label: adds labels to the x axis and file name if save is set to true, string\n",
    "    save: if True will save the plot as label_residual_plot.png, boolean\n",
    "    bins: number of bins for the histogram, integer\n",
    "\n",
    "    Returns\n",
    "    mu: the mean of the fitted normal distribution, float\n",
    "    std: the standard deviation of the fitted normal distribution, float\n",
    "    fig: the matplotlib figure containing the final graph, matplotlib figure\n",
    "    \"\"\"\n",
    "\n",
    "    x, mu, std = Fit_Gaussian(x)\n",
    "\n",
    "    norm_x = np.arange(start = np.min(x), stop = np.max(x), step = 0.0001)\n",
    "    norm_y = norm.pdf(norm_x, mu, std)\n",
    "\n",
    "    fig = plt.figure(figsize = (4, 4), dpi = 200)\n",
    "    plt.hist(x, bins = bins, density = True)\n",
    "    plt.plot(norm_x, norm_y)\n",
    "    \n",
    "    if label != \"\":\n",
    "        plt.xlabel(\"Residual in \" + label)\n",
    "\n",
    "    plt.ylabel(\"Frequency Density\")\n",
    "    plt.text(x = -0.5, y = -1.2, s = \"Mean : \" + str(mu) + \" mm\" + \"\\nSigma : \" + str(std) + \" mm\", size = 10)\n",
    "    plt.show()\n",
    "\n",
    "    if save == True:\n",
    "        plt.savfig(label + \"_residual_plot.png\")\n",
    "\n",
    "    return mu, std, fig\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def Generate_Predicted_Offset_DataFrame(df):\n",
    "\n",
    "    output_dict = {\n",
    "                    \"T_OFFSET_Y_1\": [], \"T_OFFSET_Y_2\": [], \"T_OFFSET_Y_3\": [], \"T_OFFSET_Y_4\": [], \"T_OFFSET_Y_5\": [], \"T_OFFSET_Y_6\": [], \n",
    "                    \"PRED_OFFSET_Y_1\": [], \"PRED_OFFSET_Y_2\": [], \"PRED_OFFSET_Y_3\": [], \"PRED_OFFSET_Y_4\": [], \"PRED_OFFSET_Y_5\": [], \"PRED_OFFSET_Y_6\": [], \n",
    "                    \"HIT_Y_1\": [], \"HIT_Y_2\": [], \"HIT_Y_3\": [], \"HIT_Y_4\": [], \"HIT_Y_5\": [], \"HIT_Y_6\": [], \n",
    "                    \"PRED_Y_1\": [], \"PRED_Y_2\": [], \"PRED_Y_3\": [], \"PRED_Y_4\": [], \"PRED_Y_5\": [], \"PRED_Y_6\": [], \n",
    "                    \"FIT_Y_1\": [], \"FIT_Y_2\": [], \"FIT_Y_3\": [], \"FIT_Y_4\": [], \"FIT_Y_5\": [], \"FIT_Y_6\": [], \n",
    " \n",
    "                    \"T_OFFSET_Z_1\": [], \"T_OFFSET_Z_2\": [], \"T_OFFSET_Z_3\": [], \"T_OFFSET_Z_4\": [], \"T_OFFSET_Z_5\": [], \"T_OFFSET_Z_6\": [], \n",
    "                    \"PRED_OFFSET_Z_1\": [], \"PRED_OFFSET_Z_2\": [], \"PRED_OFFSET_Z_3\": [], \"PRED_OFFSET_Z_4\": [], \"PRED_OFFSET_Z_5\": [], \"PRED_OFFSET_Z_6\": [], \n",
    "                    \"HIT_Z_1\": [], \"HIT_Z_2\": [], \"HIT_Z_3\": [], \"HIT_Z_4\": [], \"HIT_Z_5\": [], \"HIT_Z_6\": [], \n",
    "                    \"PRED_Z_1\": [], \"PRED_Z_2\": [], \"PRED_Z_3\": [], \"PRED_Z_4\": [], \"PRED_Z_5\": [], \"PRED_Z_6\": [],\n",
    "                    \"FIT_Z_1\": [], \"FIT_Z_2\": [], \"FIT_Z_3\": [], \"FIT_Z_4\": [], \"FIT_Z_5\": [], \"FIT_Z_6\": [], \n",
    "    }\n",
    "\n",
    "    for i in range(1, 7):\n",
    "\n",
    "        output_dict[\"T_OFFSET_Y_\" + str(i)] = df[\"Y_TRUTH_\" + str(i)] - df[\"GLOBAL_Y_HIT_\" + str(i)]\n",
    "        output_dict[\"HIT_Y_\" + str(i)] = df[\"GLOBAL_Y_HIT_\" + str(i)]\n",
    "        output_dict[\"FIT_Y_\" + str(i)] = df[\"FIT_Y_HIT_\" + str(i)]\n",
    "\n",
    "        output_dict[\"T_OFFSET_Z_\" + str(i)] = df[\"Z_TRUTH_\" + str(i)] - df[\"GLOBAL_Z_HIT_\" + str(i)]\n",
    "        output_dict[\"HIT_Z_\" + str(i)] = df[\"GLOBAL_Z_HIT_\" + str(i)]\n",
    "        output_dict[\"FIT_Z_\" + str(i)] = df[\"FIT_Z_HIT_\" + str(i)]\n",
    "\n",
    "        output_dict[\"PRED_Y_\" + str(i)] = np.zeros(len(df))\n",
    "        output_dict[\"PRED_OFFSET_Y_\" + str(i)] = np.zeros(len(df))\n",
    "        \n",
    "        output_dict[\"PRED_Z_\" + str(i)] = np.zeros(len(df))\n",
    "        output_dict[\"PRED_OFFSET_Z_\" + str(i)] = np.zeros(len(df))\n",
    "\n",
    "    delta_y = df[\"FIT_PY_1\"]/df[\"FIT_PX_1\"]*(df[\"GLOBAL_X_HIT_2\"].mean() - df[\"GLOBAL_X_HIT_1\"].mean())\n",
    "    delta_z = df[\"FIT_PZ_1\"]/df[\"FIT_PX_1\"]*(df[\"GLOBAL_X_HIT_2\"].mean() - df[\"GLOBAL_X_HIT_1\"].mean())\n",
    "\n",
    "    for i in range(1, 3):\n",
    "\n",
    "        PRED_Y = i * delta_y + df[\"GLOBAL_Y_HIT_1\"]\n",
    "        PRED_Z = i * delta_z + df[\"GLOBAL_Z_HIT_1\"]\n",
    "\n",
    "        output_dict[\"PRED_Y_\" + str(i+1)] = PRED_Y\n",
    "        output_dict[\"PRED_OFFSET_Y_\" + str(i+1)] = PRED_Y - df[\"GLOBAL_Y_HIT_\" + str(i+1)]\n",
    "\n",
    "        output_dict[\"PRED_Z_\" + str(i+1)] = PRED_Z \n",
    "        output_dict[\"PRED_OFFSET_Z_\" + str(i+1)] = PRED_Z - df[\"GLOBAL_Z_HIT_\" + str(i+1)]\n",
    "        \n",
    "    output_df = pd.DataFrame(output_dict)\n",
    "\n",
    "    return output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt \n",
    "\n",
    "def Summarise_DataFrame(df, offsets_y, offsets_z, plots = False):\n",
    "\n",
    "    SUM_OF_SQUARES = 0\n",
    "    SUM_OF_TRUE_SQUARES = 0\n",
    "    REL_ERR_ARRAY = [] \n",
    "    PRED_OFFSET_Y_ARRAY = []\n",
    "    PRED_OFFSET_Z_ARRAY = []\n",
    "\n",
    "    for i in range(0, 6):\n",
    "\n",
    "        PRED_OFFSET_Y = np.mean(df[\"PRED_OFFSET_Y_\" + str(i+1)][np.abs(df[\"PRED_OFFSET_Y_\" + str(i+1)]) < 1])\n",
    "        PRED_OFFSET_Z = np.mean(df[\"PRED_OFFSET_Z_\" + str(i+1)][np.abs(df[\"PRED_OFFSET_Z_\" + str(i+1)]) < 1])\n",
    "\n",
    "        TRUE_OFFSET_Y = offsets_y[i]\n",
    "        TRUE_OFFSET_Z = offsets_z[i]\n",
    "\n",
    "        RESIDUAL_Y = np.abs(PRED_OFFSET_Y) - np.abs(TRUE_OFFSET_Y)\n",
    "        RESIDUAL_Z = np.abs(PRED_OFFSET_Z) - np.abs(TRUE_OFFSET_Z)\n",
    "\n",
    "        if TRUE_OFFSET_Y != 0:\n",
    "            REL_ERR_Y = (PRED_OFFSET_Y - TRUE_OFFSET_Y)/TRUE_OFFSET_Y * 100\n",
    "        else:\n",
    "            REL_ERR_Y = np.nan\n",
    "\n",
    "        if TRUE_OFFSET_Z != 0:\n",
    "            REL_ERR_Z = (PRED_OFFSET_Z - TRUE_OFFSET_Z)/TRUE_OFFSET_Z * 100\n",
    "        else:\n",
    "            REL_ERR_Z = np.nan\n",
    "\n",
    "        print(\"OFFSET RECONSTRUCTION SUMMARY FOR TRACKING PLANE \" + str(i+1))\n",
    "        print(\"\\nY AXIS\")\n",
    "        print(\"PREDICTED OFFSET: \" + str(PRED_OFFSET_Y))\n",
    "        print(\"TRUE OFFSET: \" + str(TRUE_OFFSET_Y))\n",
    "        print(\"RESIDUAL: \" + str(RESIDUAL_Y))\n",
    "        print(\"PERCENTAGE DIFFERENCE: \" + str(REL_ERR_Y))\n",
    "        print(\"\\nZ AXIS\")\n",
    "        print(\"PREDICTED OFFSET: \" + str(PRED_OFFSET_Z))\n",
    "        print(\"RESIDUAL: \" + str(RESIDUAL_Z))\n",
    "        print(\"PERCENTAGE DIFFERENCE: \" + str(REL_ERR_Z))\n",
    "        print(\"\\n\")\n",
    "\n",
    "        SUM_OF_SQUARES += RESIDUAL_Y**2 + RESIDUAL_Z**2\n",
    "        SUM_OF_TRUE_SQUARES += TRUE_OFFSET_Y**2 + TRUE_OFFSET_Z**2\n",
    "\n",
    "        REL_ERR_ARRAY.append(REL_ERR_Y)\n",
    "        REL_ERR_ARRAY.append(REL_ERR_Z)\n",
    "        PRED_OFFSET_Y_ARRAY.append(PRED_OFFSET_Y)\n",
    "        PRED_OFFSET_Z_ARRAY.append(PRED_OFFSET_Z)\n",
    "\n",
    "        if plots == True:\n",
    "            Residual_Plot(df[\"PRED_OFFSET_Y_\" + str(i+1)], label = \"Predicted Y Offset: Plane \" + str(i+1))\n",
    "            Residual_Plot(df[\"PRED_OFFSET_Z_\" + str(i+1)], label = \"Predicted Z Offset: Plane \" + str(i+1))\n",
    "\n",
    "    print(\"OVERALL RECONSTRUCTION RESULTS\")\n",
    "    print(\"SUM OF SQUARES: \" + str(SUM_OF_SQUARES))\n",
    "    print(\"SUM OF TRUE SQUARES: \" + str(SUM_OF_TRUE_SQUARES))\n",
    "    print(\"MEAN PERCENTAGE DIFFERENCE: \" + str(np.mean(REL_ERR_ARRAY)))\n",
    "    print(\"MEDIAN PERCENTAGE DIFFERENCE: \" + str(np.median(REL_ERR_ARRAY)))\n",
    "\n",
    "    return np.array(PRED_OFFSET_Y_ARRAY), np.array(PRED_OFFSET_Z_ARRAY)\n",
    "\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Analyse_Run(input_dir, i, offsets_y, offsets_z, plots = False):\n",
    "\n",
    "    df = Generate_DataFrame_From_ROOT(input_dir, i)\n",
    "\n",
    "    df = df[df[\"CHI2SUM\"] < 50]\n",
    "\n",
    "    df_offsets = Generate_Predicted_Offset_DataFrame(df)\n",
    "\n",
    "    pred_offsets_y, pred_offsets_z = Summarise_DataFrame(df_offsets, offsets_y, offsets_z, plots)\n",
    "\n",
    "    return pred_offsets_y, pred_offsets_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Analyse_Multiple_Runs(input_dir, n_samples, offsets_y, offsets_z, plots = False):\n",
    "    \n",
    "    pred_offsets_y = np.array([])\n",
    "    pred_offsets_z = np.array([])\n",
    "\n",
    "    for i in range(0, n_samples):\n",
    "\n",
    "        print(\"\\nANALYSING DATAFRAME: \" + str(i) + \"\\n\")\n",
    "\n",
    "        pred_offsets_y_i, pred_offsets_z_i = Analyse_Run(input_dir, i, offsets_y[i], offsets_z[i], plots)\n",
    "\n",
    "        pred_offsets_y = np.append(pred_offsets_y, pred_offsets_y_i)\n",
    "        pred_offsets_z = np.append(pred_offsets_z, pred_offsets_z_i)\n",
    "\n",
    "    np.savetxt(input_dir + \"pred_offsets_y_.csv\", pred_offsets_y, delimiter = \",\")\n",
    "    np.savetxt(input_dir + \"pred_offsets_z_.csv\", pred_offsets_z, delimiter = \",\")\n",
    "\n",
    "    return pred_offsets_y, pred_offsets_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ANALYSING DATAFRAME: 0\n",
      "\n",
      "OFFSET RECONSTRUCTION SUMMARY FOR TRACKING PLANE 1\n",
      "\n",
      "Y AXIS\n",
      "PREDICTED OFFSET: 0.0\n",
      "TRUE OFFSET: -0.0\n",
      "RESIDUAL: 0.0\n",
      "PERCENTAGE DIFFERENCE: nan\n",
      "\n",
      "Z AXIS\n",
      "PREDICTED OFFSET: 0.0\n",
      "RESIDUAL: 0.0\n",
      "PERCENTAGE DIFFERENCE: nan\n",
      "\n",
      "\n",
      "OFFSET RECONSTRUCTION SUMMARY FOR TRACKING PLANE 2\n",
      "\n",
      "Y AXIS\n",
      "PREDICTED OFFSET: -0.04993509562377971\n",
      "TRUE OFFSET: -0.05\n",
      "RESIDUAL: -6.490437622029555e-05\n",
      "PERCENTAGE DIFFERENCE: -0.1298087524405911\n",
      "\n",
      "Z AXIS\n",
      "PREDICTED OFFSET: -0.0029312411714433936\n",
      "RESIDUAL: 0.0029312411714433936\n",
      "PERCENTAGE DIFFERENCE: nan\n",
      "\n",
      "\n",
      "OFFSET RECONSTRUCTION SUMMARY FOR TRACKING PLANE 3\n",
      "\n",
      "Y AXIS\n",
      "PREDICTED OFFSET: -0.0027343691688305007\n",
      "TRUE OFFSET: -0.0\n",
      "RESIDUAL: 0.0027343691688305007\n",
      "PERCENTAGE DIFFERENCE: nan\n",
      "\n",
      "Z AXIS\n",
      "PREDICTED OFFSET: -0.0033724718101562166\n",
      "RESIDUAL: 0.0033724718101562166\n",
      "PERCENTAGE DIFFERENCE: nan\n",
      "\n",
      "\n",
      "OFFSET RECONSTRUCTION SUMMARY FOR TRACKING PLANE 4\n",
      "\n",
      "Y AXIS\n",
      "PREDICTED OFFSET: 0.0\n",
      "TRUE OFFSET: -0.0\n",
      "RESIDUAL: 0.0\n",
      "PERCENTAGE DIFFERENCE: nan\n",
      "\n",
      "Z AXIS\n",
      "PREDICTED OFFSET: 0.0\n",
      "RESIDUAL: 0.0\n",
      "PERCENTAGE DIFFERENCE: nan\n",
      "\n",
      "\n",
      "OFFSET RECONSTRUCTION SUMMARY FOR TRACKING PLANE 5\n",
      "\n",
      "Y AXIS\n",
      "PREDICTED OFFSET: 0.0\n",
      "TRUE OFFSET: -0.0\n",
      "RESIDUAL: 0.0\n",
      "PERCENTAGE DIFFERENCE: nan\n",
      "\n",
      "Z AXIS\n",
      "PREDICTED OFFSET: 0.0\n",
      "RESIDUAL: 0.0\n",
      "PERCENTAGE DIFFERENCE: nan\n",
      "\n",
      "\n",
      "OFFSET RECONSTRUCTION SUMMARY FOR TRACKING PLANE 6\n",
      "\n",
      "Y AXIS\n",
      "PREDICTED OFFSET: 0.0\n",
      "TRUE OFFSET: -0.0\n",
      "RESIDUAL: 0.0\n",
      "PERCENTAGE DIFFERENCE: nan\n",
      "\n",
      "Z AXIS\n",
      "PREDICTED OFFSET: 0.0\n",
      "RESIDUAL: 0.0\n",
      "PERCENTAGE DIFFERENCE: nan\n",
      "\n",
      "\n",
      "OVERALL RECONSTRUCTION RESULTS\n",
      "SUM OF SQUARES: 2.7446728244966535e-05\n",
      "SUM OF TRUE SQUARES: 0.0025000000000000005\n",
      "MEAN PERCENTAGE DIFFERENCE: nan\n",
      "MEDIAN PERCENTAGE DIFFERENCE: nan\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([ 0.        , -0.0499351 , -0.00273437,  0.        ,  0.        ,\n",
       "         0.        ]),\n",
       " array([ 0.        , -0.00293124, -0.00337247,  0.        ,  0.        ,\n",
       "         0.        ]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Analyse_Multiple_Runs(input_dir, n_samples, -offsets_y, offsets_z)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mphys_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
